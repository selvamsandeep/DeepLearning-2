{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2 \n",
    "import glob\n",
    "import os \n",
    "import gc; gc.enable()\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from subprocess import check_output\n",
    "print(check_output(['ls', 'input']).decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_img_path = 'input/train_/'\n",
    "test_img_path = 'input/test_/'\n",
    "IMG_WIDTH = 128\n",
    "IMG_HIGHT = 128\n",
    "le = LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_img_cv2(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    resized = cv2.resize(img,(IMG_WIDTH, IMG_HIGHT), cv2.INTER_LINEAR)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train():\n",
    "    X_train = []    \n",
    "    img_names = train.image_name.values.tolist()\n",
    "    for img_name in tqdm(img_names):\n",
    "        img = get_img_cv2(train_img_path+img_name)\n",
    "        X_train.append(img)\n",
    "    X_train_id = train.row_id.values.tolist()\n",
    "    X_train = np.array(X_train, dtype=np.int8)\n",
    "    y_train = le.fit_transform(train.detected.values).astype(np.int8)\n",
    "    \n",
    "    return X_train, y_train, X_train_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test():\n",
    "    X_test = []   \n",
    "    img_names = test.image_name.values.tolist()\n",
    "    for img_name in tqdm(img_names):\n",
    "        img = get_img_cv2(test_img_path+img_name)\n",
    "        X_test.append(img)\n",
    "        \n",
    "    X_test = np.array(X_test, dtype=np.int8)   \n",
    "    test_id = test.row_id.values\n",
    "    \n",
    "    return X_test, test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_and_normalise_train():\n",
    "    train_img, train_target, train_id = load_train()\n",
    "    \n",
    "    print('Reshape train_img for Tensorflow...')\n",
    "    train_img = train_img.transpose((0, 1, 2, 3))\n",
    "    \n",
    "    print('convert to float and normalize....')\n",
    "    train_img = train_img.astype(np.float32)\n",
    "    train_img = train_img/255.\n",
    "    train_target = np_utils.to_categorical(train_target, 14) \n",
    "    \n",
    "    print('Train shpae: {} Train target shape: {}'.format(train_img.shape, train_target.shape))\n",
    "    \n",
    "    return train_img, train_target, train_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_and_normalise_test():\n",
    "    test_img, test_id = load_test()\n",
    "    \n",
    "    print('Resahpe test_img for Tesnorflow...')\n",
    "    test_img = test_img.transpose((0, 1, 2, 3))\n",
    "    \n",
    "    print('convert to float and normalize...')\n",
    "    test_img = test_img.astype(np.float32)\n",
    "    test_img = test_img/255.\n",
    "    \n",
    "    print('Test shpae: {}'.format(test_img.shape))\n",
    "    return test_img, test_id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1), input_shape =(128, 128, 3)))\n",
    "    model.add(Convolution2D(4, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(4, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(8, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(8, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))    \n",
    "    #model.add(Dense(512, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Dense(1024, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(14, activation='softmax'))\n",
    "\n",
    "    sgd = SGD(lr= 1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_cv_create_model(n_folds = 2):\n",
    "    \n",
    "    batch_size = 16\n",
    "    nb_epoch = 30\n",
    "    random_state = 31\n",
    "    \n",
    "    train_img, train_target, train_id = read_and_normalise_train()\n",
    "    \n",
    "    kf = KFold(len(train_id), n_folds=n_folds, shuffle=True, random_state=random_state )\n",
    "    yfull_train = {}\n",
    "    n_fold = 0\n",
    "    sum_score = 0\n",
    "    models =[]   \n",
    "    \n",
    "    for train_idx, valid_idx in kf:\n",
    "        model = create_model()\n",
    "        X_train = train_img[train_idx]\n",
    "        y_train = train_target[train_idx]\n",
    "        X_valid = train_img[valid_idx]\n",
    "        y_valid = train_target[valid_idx]\n",
    "        \n",
    "        n_fold += 1\n",
    "        print('Start fold num {} from {}'.format(n_fold, n_folds))\n",
    "        print('Train fold {} traget fold {}'.format(len(X_train), len(y_train)))\n",
    "        print('valid fold {} traget fold {}'.format(len(X_valid), len(y_valid)))\n",
    "        \n",
    "        callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=0)]\n",
    "        \n",
    "        model.fit(X_train, y_train, batch_size=batch_size, epochs=nb_epoch, shuffle=True,\n",
    "                    verbose=2, validation_data = (X_valid, y_valid), callbacks=callbacks)\n",
    "        \n",
    "        predict_valid = model.predict(X_valid.astype(np.float32), batch_size=batch_size, verbose=2)\n",
    "        \n",
    "        score = f1_score(y_valid.argmax(axis=1), predict_valid.argmax(axis=1), average='weighted')\n",
    "        print('F1 score: ', score)\n",
    "        sum_score += score*len(valid_idx)\n",
    "        \n",
    "        for i in range(len(valid_idx)):\n",
    "            yfull_train[valid_idx[i]] = predict_valid[i]            \n",
    "             \n",
    "        models.append(model)\n",
    "        \n",
    "    score = sum_score/len(train_img)\n",
    "    print('F1 Score train independent avg {}'.format(score))\n",
    "    \n",
    "    info_str = 'f1_' + str(round(score, 3)) + '_folds_' + str(n_folds) + '_ep_' + str(nb_epoch)\n",
    "    return info_str, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_several_folds_mean(data, nfolds):\n",
    "    a = np.array(data[0])\n",
    "    for i in range(1, nfolds):\n",
    "        a += np.array(data[i])\n",
    "    a /= nfolds\n",
    "    return a.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv_process_test(models):\n",
    "    batch_size = 16\n",
    "    n_fold = 0\n",
    "    yfull_test = []\n",
    "    n_folds =len(models)\n",
    "    \n",
    "    for i in range(n_folds):\n",
    "        model = models[i]\n",
    "        n_fold += 1\n",
    "        print('Start KFold number {} from {}'.format(n_fold, n_folds))\n",
    "        test_img, test_id = read_and_normalise_test()\n",
    "        test_pred = model.predict(test_img, batch_size=batch_size, verbose=2)\n",
    "        yfull_test.append(test_pred)\n",
    "        \n",
    "    test_res = merge_several_folds_mean(yfull_test, n_folds)    \n",
    "    \n",
    "    return test_res, test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_str, models = run_cv_create_model(2)\n",
    "#del train_data, train_target, train_id, test_img, test_id\n",
    "\n",
    "test_res, test_id = run_cv_process_test(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = le.inverse_transform(np.array(test_res).argmax(axis=1))\n",
    "sub = pd.DataFrame({'row_id':test_id, 'detected':pred})\n",
    "sub = sub[['row_id', 'detected']]\n",
    "sub.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(info_str+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.detected.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
