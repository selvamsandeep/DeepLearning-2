{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_maps.json\n",
      "sample_submission.csv\n",
      "test_\n",
      "test.csv\n",
      "train_\n",
      "train.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## import libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os, sys\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras import __version__\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from subprocess import check_output\n",
    "print(check_output(['ls', 'input']).decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_img_path = 'input/train_/'\n",
    "test_img_path = 'input/test_/'\n",
    "IM_WIDTH, IM_HEIGHT = 139, 139 #fixed size for InceptionV3\n",
    "NB_EPOCHS = 10\n",
    "BAT_SIZE = 32\n",
    "FC_SIZE = 1024\n",
    "NB_IV3_LAYERS_TO_FREEZE = 120\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_img_cv2(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    resized = cv2.resize(img,(IM_WIDTH, IM_HEIGHT), cv2.INTER_LINEAR)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train():\n",
    "    X_train = []    \n",
    "    img_names = train.image_name.values.tolist()\n",
    "    for img_name in tqdm(img_names):\n",
    "        img = get_img_cv2(train_img_path+img_name)\n",
    "        X_train.append(img)\n",
    "    X_train_id = train.row_id.values.tolist()\n",
    "    X_train = np.array(X_train, dtype=np.int8)\n",
    "    y_train = le.fit_transform(train.detected.values).astype(np.int8)\n",
    "    \n",
    "    return X_train, y_train, X_train_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test():\n",
    "    X_test = []   \n",
    "    img_names = test.image_name.values.tolist()\n",
    "    for img_name in tqdm(img_names):\n",
    "        img = get_img_cv2(test_img_path+img_name)\n",
    "        X_test.append(img)\n",
    "        \n",
    "    X_test = np.array(X_test, dtype=np.int8)   \n",
    "    test_id = test.row_id.values\n",
    "    \n",
    "    return X_test, test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_and_normalise_train():\n",
    "    train_img, train_target, train_id = load_train()\n",
    "    \n",
    "    print('Reshape train_img for Tensorflow...')\n",
    "    train_img = train_img.transpose((0, 1, 2, 3))\n",
    "    \n",
    "    print('convert to float and normalize....')\n",
    "    train_img = train_img.astype(np.float32)\n",
    "    train_img = train_img/255.\n",
    "    train_target = to_categorical(train_target, 14) \n",
    "    \n",
    "    print('Train shpae: {} Train target shape: {}'.format(train_img.shape, train_target.shape))\n",
    "    \n",
    "    return train_img, train_target, train_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_and_normalise_test():\n",
    "    test_img, test_id = load_test()\n",
    "    \n",
    "    print('Resahpe test_img for Tesnorflow...')\n",
    "    test_img = test_img.transpose((0, 1, 2, 3))\n",
    "    \n",
    "    print('convert to float and normalize...')\n",
    "    test_img = test_img.astype(np.float32)\n",
    "    test_img = test_img/255.\n",
    "    \n",
    "    print('Test shpae: {}'.format(test_img.shape))\n",
    "    return test_img, test_id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18577/18577 [03:41<00:00, 83.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshape train_img for Tensorflow...\n",
      "convert to float and normalize....\n",
      "Train shpae: (18577, 139, 139, 3) Train target shape: (18577, 14)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, train_id = read_and_normalise_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer learning with Inception V3 \n",
    "#include_top=False excludes final FC layer\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(IM_WIDTH, IM_HEIGHT, 3))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## set model architechture \n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(FC_SIZE, activation='relu')(x) #new FC layer, random init\n",
    "predictions = Dense(y_train.shape[1], activation='softmax')(x) #new softmax layer\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen =  ImageDataGenerator(\n",
    "      preprocessing_function=preprocess_input,\n",
    "      rotation_range=30,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(\n",
    "    X_train, y_train,\n",
    "    #target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "    batch_size=BAT_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "581/580 [==============================] - 70s - loss: 2.3491 - acc: 0.2845    \n",
      "Epoch 2/10\n",
      "581/580 [==============================] - 68s - loss: 2.1873 - acc: 0.3069    \n",
      "Epoch 3/10\n",
      "581/580 [==============================] - 67s - loss: 2.1718 - acc: 0.3079    \n",
      "Epoch 4/10\n",
      "581/580 [==============================] - 67s - loss: 2.1679 - acc: 0.3087    \n",
      "Epoch 5/10\n",
      "581/580 [==============================] - 67s - loss: 2.1575 - acc: 0.3130    \n",
      "Epoch 6/10\n",
      "581/580 [==============================] - 66s - loss: 2.1646 - acc: 0.3114    \n",
      "Epoch 7/10\n",
      "581/580 [==============================] - 66s - loss: 2.1598 - acc: 0.3112    \n",
      "Epoch 8/10\n",
      "581/580 [==============================] - 66s - loss: 2.1566 - acc: 0.3130    \n",
      "Epoch 9/10\n",
      "581/580 [==============================] - 65s - loss: 2.1520 - acc: 0.3152    \n",
      "Epoch 10/10\n",
      "581/580 [==============================] - 65s - loss: 2.1551 - acc: 0.3125    \n"
     ]
    }
   ],
   "source": [
    "history_tl = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=NB_EPOCHS,\n",
    "    steps_per_epoch=X_train.shape[0]/BAT_SIZE,     \n",
    "    class_weight='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
    "     layer.trainable = False\n",
    "for layer in model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
    "     layer.trainable = True\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "580/580 [==============================] - 128s - loss: 2.1341 - acc: 0.3120   \n",
      "Epoch 2/10\n",
      "580/580 [==============================] - 127s - loss: 2.1180 - acc: 0.3185   \n",
      "Epoch 3/10\n",
      "580/580 [==============================] - 127s - loss: 2.1131 - acc: 0.3169   \n",
      "Epoch 4/10\n",
      "580/580 [==============================] - 126s - loss: 2.0959 - acc: 0.3200   \n",
      "Epoch 5/10\n",
      "580/580 [==============================] - 124s - loss: 2.0898 - acc: 0.3256   \n",
      "Epoch 6/10\n",
      "580/580 [==============================] - 125s - loss: 2.0877 - acc: 0.3229   \n",
      "Epoch 7/10\n",
      "580/580 [==============================] - 125s - loss: 2.0821 - acc: 0.3273   \n",
      "Epoch 8/10\n",
      "580/580 [==============================] - 125s - loss: 2.0724 - acc: 0.3268   \n",
      "Epoch 9/10\n",
      "580/580 [==============================] - 125s - loss: 2.0741 - acc: 0.3262   \n",
      "Epoch 10/10\n",
      "580/580 [==============================] - 122s - loss: 2.0644 - acc: 0.3286   \n"
     ]
    }
   ],
   "source": [
    "history_ft = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=NB_EPOCHS,\n",
    "    steps_per_epoch=X_train.shape[0]// BAT_SIZE,    \n",
    "    class_weight='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12386/12386 [02:33<00:00, 80.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resahpe test_img for Tesnorflow...\n",
      "convert to float and normalize...\n",
      "Test shpae: (12386, 139, 139, 3)\n"
     ]
    }
   ],
   "source": [
    "X_test, test_id = read_and_normalise_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(preprocess_input(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_100</td>\n",
       "      <td>class_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_10002</td>\n",
       "      <td>class_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_10005</td>\n",
       "      <td>class_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_10008</td>\n",
       "      <td>class_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_10009</td>\n",
       "      <td>class_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_id detected\n",
       "0    id_100  class_3\n",
       "1  id_10002  class_3\n",
       "2  id_10005  class_5\n",
       "3  id_10008  class_3\n",
       "4  id_10009  class_3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = le.inverse_transform(np.argmax(pred, axis=1))\n",
    "sub = pd.DataFrame({'row_id':test_id, 'detected':pred})\n",
    "sub = sub[['row_id', 'detected']]\n",
    "sub.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('incepv3_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class_3', 'class_5', 'class_7', 'class_12'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.detected.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
